## 初步检索

### CAT
- 查看所有节点（v是用来要求在结果中返回表头）
```
GET /_cat/nodes?v
```
- 查看es健康状况
```
GET /_cat/health
```
- 查看主节点
```
GET /_cat/master
```
- 查看所有索引 ，等价于mysql数据库的show databases
```
GET /_cat/indicies
```

## 索引管理

### 创建索引
- 创建一个名为twitter的索引，设置索引的分片数为3，备份数为2
- 注意：在ES中创建一个索引类似于在数据库中创建一个表
- 说明：
    - 默认的分片数是5到1024
    - 默认的备份数是1
    - 索引的名称必须是小写的，不可重名

```
PUT twitter
{
  "settings": {
    "number_of_shards": 3,
    "number_of_replicas": 2
  }
}
```

### 创建mapping映射
- 在ES中创建一个mapping映射类似于在数据库中定义表结构，即表里面有哪些字段、字段是什么类型、字段的默认值等
```
PUT twitter
{
  "settings": {
    "index": {
      "number_of_shards": 3,
      "number_of_replicas": 2
    }
  },
  "mappings": {
    "properties": {
      "age": {
        "type": "integer"
      },
      "email": {
        "type": "keyword"
      },
      "name": {
        "type": "text"
      }
    }
  }
}
```

### 数据迁移
```
POST _reindex
{
  "source":{
      "index":"bank"
   },
  "dest":{
      "index":"newbank"
   }
}
```

### 创建索引时加入别名定义
```
PUT twitter
{
  "aliases": {
    "alias_1": {},
    "alias_2": {
      "filter": {
        "term": {
          "user": "kimchy"
        }
      },
      "routing": "kimchy"
    }
  }
}
```
### 查看索引的定义信息
```
GET /twitter // 可以一次获取多个索引（以逗号间隔） 获取所有索引 _all 或 用通配符*
GET /twitter/_settings
GET /twitter/_mapping
```

### 删除索引
- 可以一次删除多个索引（以逗号间隔） 删除所有索引 _all 或 通配符 *
```
DELETE /twitter
```
### 判断索引是否存在
 HTTP status code 表示结果 404 不存在 ， 200 存在
```
HEAD twitter
```

### 修改备份数
```
PUT /twitter/_settings
{
  "index": {
    "number_of_replicas": 1
  }
}
```

### 设置回默认值，用null
```
PUT /twitter/_settings
{
  "index": {
    "refresh_interval": null
  }
}
```

### 设置索引的读写
index.blocks.read_only：设为true,则索引以及索引的元数据只可读
index.blocks.read_only_allow_delete：设为true，只读时允许删除
index.blocks.read：设为true，则不可读
index.blocks.write：设为true，则不可写
index.blocks.metadata：设为true，则索引元数据不可读写
```
PUT /twitter/_settings
{
  "index": {
    "blocks.read_only": true
  }
}
```

### 索引模板
- 在创建索引时，为每个索引写定义信息可能是一件繁琐的事情，ES提供了索引模板功能，让你可以定义一个索引模板，模板中定义好settings、mapping、以及一个模式定义来匹配创建的索引
- 注意：模板只在索引创建时被参考，修改模板不会影响已创建的索引
```
// 新增/修改名为tempae_1的模板，匹配名称为te* 或 bar*的索引创建：
PUT _template/template_1
{
  "index_patterns": [
    "te*",
    "bar*"
  ],
  "settings": {
    "number_of_shards": 1
  },
  "mappings": {
    "properties": {
      "age": {
        "type": "integer"
      },
      "email": {
        "type": "keyword"
      },
      "name": {
        "type": "text"
      }
    }
  }
}
```
### 查看索引模板
```
GET /_template/template_1
GET /_template/temp* 
GET /_template/template_1,template_2
GET /_template
```

### 删除模板
```
DELETE /_template/template_1
```

###   打开/关闭索引
- 关闭的索引不能进行读写操作，几乎不占集群开销
- 关闭的索引可以打开，打开走的是正常的恢复流程
```
POST /my_index/_close
POST /my_index/_open
```

### 收缩索引
- 索引的分片数是不可更改的，如要减少分片数可以通过收缩方式收缩为一个新的索引
- 新索引的分片数必须是原分片数的因子值（即原分片数量是新分片倍数），如原分片数是8，则新索引的分片数可以为4、2、1
- **收缩前的准备工作：**
	- 将原索引设置为只读
	- 将原索引各分片的一个副本重分配到同一个节点上，并且要是健康绿色状态
- **收缩的流程：**
    - 先把所有主分片都转移到一台主机上
    - 在这台主机上创建一个新索引，分片数较小，其他设置和原索引一致
    - 把原索引的所有分片，复制（或硬链接）到新索引的目录下
    - 对新索引进行打开操作恢复分片数据
    - (可选)重新把新索引的分片均衡到其他节点上
```
PUT /my_source_index/_settings
{
  "settings": {
    // 指定进行收缩的节点的名称
    "index.routing.allocation.require._name": "shrink_node_name",
    // 阻止写，只读
    "index.blocks.write": true
  }
}
// 进行收缩：
POST my_source_index/_shrink/my_target_index
{
  "settings": {
    "index.number_of_replicas": 1,
    "index.number_of_shards": 1,
    "index.codec": "best_compression"
  }}
// 监控收缩过程：
GET _cat/recovery?v
GET _cluster/health
```

### 拆分索引
- 当索引的分片容量过大时，可以通过拆分操作将索引拆分为一个`倍数`分片数的新索引
- 当最初设置的索引的分片数不够用时就需要拆分索引了，和压缩索引相反
```
// 先设置索引只读
PUT /my_source_index/_settings
{
  "settings": {
    "index.blocks.write": true
  }
}
// 做拆分
POST my_source_index/_split/my_target_index
{
  "settings": {
    "index.number_of_shards": 2
  }
}
// 监控拆分过程：
GET _cat/recovery?v
GET _cluster/health
```

## 索引状态管理

### 清理缓存
- 默认会清理所有缓存，可指定清理query, fielddata or request 缓存
```
POST /twitter/_cache/clear
POST /kimchy,elasticsearch/_cache/clear
POST /_cache/clear
```

### 手动refresh
```
POST /kimchy,elasticsearch/_refresh
POST /_refresh
```

### 手动flush
```
POST twitter/_flush
```
### 强制段合并
- 可选参数说明：
    - max_num_segments 合并为几个段，默认1
    - only_expunge_deletes 是否只合并含有删除文档的段，默认false
    - flush 合并后是否刷新，默认true
```
POST /kimchy,elasticsearch/_forcemerge
POST /_forcemerge
POST /kimchy/_forcemerge?only_expunge_deletes=false&max_num_segments=100&flush=true
```

## 文档管理

### 新增文档
- **POST：** 
	- 如果不指定id，会`自动生成id`
	- 指定id就会修改这个数据，并新增版本号
- **PUT：** 
	- PUT`必须指定id`
	- 由于PUT需要指定id，我们一般用来做修改操作，不指定id会报错
```
POST customer/_doc/1
{
 "name":"John Doe"
}
POST customer/_doc
{
 "name":"John Doe"
}
PUT customer/_doc/1
{
 "name":"John Doe"
}
```

### 更新文档
- **POST：** 
    - 带_update的请求，会对比doc内容是否相同，如果相同，则不会增加`_seq_no`或者`version`
    - 每次操作都会重新保存数据，会增加`_seq_no`或者`version`
- **PUT：** 
	- 每次操作都会重新保存数据，会增加`_seq_no`或者`version`
```
POST customer/_update/1
{
  "doc": {
    "name":"arthas"
  }
}
POST customer/_doc/1
{
 "name":"John Doe"
}
PUT customer/_doc/1
{
 "name":"John Doe"
}
```

#### 乐观锁
- 通过`if_seq_no=1&if_primary_term=1`，当序列号匹配的时候，才进行修改，否则不修改
```
POST customer/_update/1?if_seq_no=9&if_primary_term=1
{
  "doc": {
    "name":"arthas"
  }
}
POST customer/_doc/1?if_seq_no=9&if_primary_term=1
{
 "name":"John Doe"
}
PUT customer/_doc/1?if_seq_no=9&if_primary_term=1
{
 "name":"John Doe"
}
```

### 删除文档
```
DELETE customer/external/1
```
### 批量操作
- 这里的批量操作，当发生某一条执行发生失败时，其他的数据仍然能够接着执行，也就是说彼此之间是独立的
- bulk api以此按顺序执行所有的action（动作）
- 如果一个单个的动作因任何原因失败，它将继续处理它后面剩余的动作
- 当bulk api返回时，它将提供每个动作的状态（与发送的顺序相同），所以您可以检查是否一个指定的动作是否失败了
```
// {action:{metadata}}\n
// {request body  }\n
POST customer/_bulk
{"index":{"_id":"1"}}
{"name":"arthas"}
{"index":{"_id":"2"}}
{"name":"mike"}
POST /_bulk
{"delete":{"_index":"customer","_id":"1"}}
{"create":{"_index":"customer","_id":"1"}}
{"title":"my first blog post"}
{"index":{"_index":"customer"}}
{"title":"my second blog post"}
{"update":{"_index":"customer","_id":"2"}}
{"doc":{"title":"my updated blog post"}}
```

### 查询文档

#### 查询一个文档
```
GET bank/_doc/1
```

#### 基本查询
- match_all查询类型【代表查询所有的所有】，es中可以在query中组合非常多的查询类型完成复杂查询
- 除了query参数之外，我们可也传递其他的参数以改变查询结果，如sort，size
- from+size限定，完成分页功能
- sort排序，多字段排序，会在前序字段相等时后续字段内部排序，否则以前序为准
```
GET bank/_search
{
  "query": {
    "match_all": {}
  },
  "from": 0,
  "size": 5,
  "sort": [
    {
      "age": {
        "order": "desc"
      },
      "account_number": {
        "order": "desc"
      }
    }
  ]
}
```

#### 返回部分字段
```
GET bank/_search
{
  "query": {
    "match_all": {}
  },
  "_source": ["balance","firstname"]
}
```

#### match匹配查询
- 进行搜索的时候，`会先进行分词拆分`，拆完后，再来匹配，拆分后的词属于或的关系，只要任何一个词条在里面就能匹配到
- 基本类型（非字符串），精确匹配
- 字符串，全文检索，最终会按照评分进行排序，会对检索条件进行分词匹配
- 文本字段的匹配，`使用keyword`，匹配的条件就是要显示字段的全部值，要进行精确匹配的
```
GET bank/_search
{
  "query": {
    "match": {
      "account_number": "20"
    }
  }
}
GET bank/_search
{
  "query": {
    "match": {
      "address": "kings"
    }
  }
}
GET bank/_search
{
  "query": {
    "match": {
      "address.keyword": "990 Mill"
    }
  }
}
```
#### match_phrase短句匹配
- ES引擎首先分析查询字符串，从分析后的文本中构建短语查询，这意味着必须`匹配短语中的所有分词，并且保证各个分词的相对位置不变`
- 相当于查询所有`包含该短语`的文档
```
GET bank/_search
{
  "query": {
    "match_phrase": {
      "address": "mill road"
    }
  }
}
```

#### multi_math多字段匹配
- state或者address中包含mill，并且在查询过程中，会对于查询条件`进行分词`
```
GET bank/_search
{
  "query": {
    "multi_match": {
      "query": "mill",
      "fields": [
        "state",
        "address"
      ]
    }
  }
}
```

#### bool复合查询
- **must：** 必须达到must所列举的所有条件
- **must_not：** 必须不匹配must_not所列举的所有条件
- **should：** 应该达到should列举的条件
- **filter：** 结果过滤，不计算相关性得分，性能较高
- 文档是否符合每个`must`或`should`子句中的标准，决定了文档的`相关性得分`，得分越高，文档越符合您的搜索条件，默认情况下，Elasticsearch返回根据这些相关性得分排序的文档
- `must_not`子句中的条件被视为`过滤器`，它影响文档是否包含在结果中，但不影响文档的评分方式， 还可以显式地指定任意过滤器来包含或排除基于结构化数据的文档
```
GET bank/_search
{
  "query": {
    "bool": {
      "must": [
        {
          "match": {
            "gender": "M"
          }
        },
        {
          "match": {
            "address": "mill"
          }
        }
      ],
      "must_not": [
        {
          "match": {
            "age": "18"
          }
        }
      ],
      "should": [
        {
          "match": {
            "lastname": "Wallace"
          }
        }
      ]
    }
  }
}
GET bank/_search
{
  "query": {
    "bool": {
      "filter": {
        "range": {
          "balance": {
            "gte": "10000",
            "lte": "20000"
          }
        }
      }
    }
  }
}
```

#### term
- term query会去倒排索引中寻找确切的term，它并不知道分词器的存在，这种查询适合keyword、numeric、date等明确值的
```
GET bank/_search
{
  "query": {
    "term": {
      "address": "mill Road"
    }
  }
}
```

#### Aggregation执行聚合
- 聚合提供了从数据中分组和提取数据的能力
- 最简单的聚合方法大致等于SQL Group by和SQL聚合函数
- 在elasticsearch中，执行搜索返回this（命中结果），并且同时返回聚合结果，把以响应中的所有hits（命中结果）分隔开的能力
- 这是非常强大且有效的，你可以执行查询和多个聚合，并且在一次使用中得到各自的（任何一个的）返回结果，使用一次简洁和简化的API避免网络往返
```
// size:0不显示搜索数据
// aggs：执行聚合。聚合语法如下：
//    "aggs":{
//        "aggs_name这次聚合的名字，方便展示在结果集中":{
//            "AGG_TYPE聚合的类型(avg,term,terms)":{}
//         }
//    }
GET bank/_search
{
  "query": {
    "match_all": {}
  },
  "aggs": {
    "ageAgg": {
      "terms": {
        "field": "age",
        "size": 100
      },
      "aggs": {
        "balanceAgg": {
          "avg": {
            "field": "balance"
          }
        }
      }
    }
  },
  "size": 0
}
```







**搜索address中包含mill的所有人
