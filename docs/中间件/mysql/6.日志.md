## binlog（归档日志）
### 介绍
- binlog 是 MySQL 的 Server 层实现的，`所有引擎都可以使用`
- binlog 是`逻辑日志`， 记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”
- binlog 是可以追加写入的，“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并`不会覆盖以前的日志`

### 三种格式对比 
- **statement：**
    - 记录执行的sql
    - 可能会出现`主备不一致`的情况（例如插入时使用了Date函数）
- **row：**
    - 记录每行的变更情况
    - 很占空间
    - `建议使用，便于数据恢复`
- **mixed：**
    - MySQL 自己会判断这条 SQL 语句是否可能引起主备不一致，如果有可能，就用 row 格 式，否则就用 statement 格式

### 写入文件机制
![image](6.日志.assets/9505)
- 事务执行过程中，先把日志写到 binlog cache
- 事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog files 中，并清空 binlog cache
- 根据参数`sync_binlog`将binlog files的内容fsync到磁盘中

### 参数
- binlog_cache_size
    - 一个事务的 binlog 是不能被拆开的，因此不论这个事务多大，也要确保一次性写入
    - 系统给 binlog cache 分配了一片内存，`每个线程一个`，参数 binlog_cache_size 用于控制单个 线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。
- sync_binlog
    - 0，只 write，不 fsync
    - 1，只 fsync
    - N，表示每次提交事务都 write，但累积 N 个事务后才 fsync
    - 因此，在出现 IO 瓶颈的场景里，将 sync_binlog 设置成一个比较大的值，可以提升性能。在实际的业务场景中，考虑到丢失日志量的可控性，一般不建议将这个参数设成 0，比较常见的是将 其设置为 100~1000 中的某个数值，但是，将 sync_binlog 设置为 N，对应的风险是：如果主机发生异常重启，会丢失最近 N 个事 务的 binlog 日志

## redo log

### 介绍
- redo log 是 InnoDB 引擎`特有`
- redo log 是物理日志，记录的是`在某个数据页上做了什么修改`
- redo log 是`循环写`的，空间固定会用完
- redo log 主要节省的是随机写磁盘的IO消耗(转成顺序写)

### 写文件流程
![image](6.日志.assets/9433)
- 从头开始写，写到末尾就又回到开头循环写
- wirte pos是当前记录的位置，一边写一边后移
- checkpoint是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件
- checkpoint的前面是已经同步到磁盘的数据
- 当write pos追上checkpoint的时候，代表文件已满，不能再更新，需要先同步一波数据，后移checkpoint

### 刷脏页
- 当我们要往数据库插入一条数据、或者要更新一条数据的时候，我们知道数据库会在内存中把对应字段的数据更新了，但是更新之后，这些更新的字段并不会马上同步持久化到磁盘中去，而是`把这些更新的记录写入到 redo log 日记中去，等到空闲的时候，在通过 redo log 里的日记把最新的数据同步到磁盘中去`
- 当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为`脏页`。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为`干净页`

#### 刷脏页有下面4种场景（后两种不用太关注“性能”问题）：
- **redolog写满了：** redo log 里的容量是有限的，如果数据库一直很忙，更新又很频繁，这个时候 redo log 很快就会被写满了，这个时候就没办法等到空闲的时候再把数据同步到磁盘的，只能暂停其他操作，全身心来把数据同步到磁盘中去的，而这个时候，就会导致我们平时正常的SQL语句突然执行的很慢，所以说，数据库在在同步数据到磁盘的时候，就有可能导致我们的SQL语句执行的很慢了
- **内存不够用了：** 如果一次查询较多的数据，恰好碰到所查数据页不在内存中时，需要申请内存，而此时恰好内存不足的时候就需要淘汰一部分内存数据页，如果是干净页，就直接释放，如果恰好是脏页就需要刷脏页
- **MySQL 认为系统“空闲”的时候：** 这时系统没什么压力。
- **MySQL 正常关闭的时候：** 这时候，MySQL 会把内存的脏页都 flush 到磁盘上，这样下次 MySQL 启动的时候，就可以直接从磁盘上读数据，启动速度会很快

### 崩溃恢复
- 在崩溃恢复场景中，InnoDB 如果判断到一个数据页可能在崩溃恢复的时候丢失了更新，就会将它读到内存，然后让 redo log 更新内存内容。更新完成后，内存页变成脏页，然后等待`刷脏页`执行

### 参数
- innodb_flush_log_at_trx_commit
    - 0，不write也不fsync，表示每次事务提交时都只是把 redo log 留在 `redo log buffer` 中 （mysql程序挂掉，系统没挂，会丢失数据）
    - 1，只fsync，表示每次事务提交时都将 redo log 直接持久化到`磁盘`
    - 2，只write不fsync，表示每次事务提交时都只是把 redo log 写到 `page cache`（mysql程序挂掉，系统没挂，就不会丢失数据）
    - InnoDB 有一个后台线程，每隔 1 秒，就会把 redo log buffer 中的日志，调用 write 写到文件 系统的 page cache，然后调用 fsync 持久化到磁盘

## 日志记录流程
![image](6.日志.assets/9533)
### 两阶段提交（2PC）
- 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内 存，然后再返回
- 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的 一行数据，再调用引擎接口写入这行新数据
- 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于`prepare`状态。然后告知执行器执行完成了，随时可以提交事务
- 执行器生成这个操作的 binlog，并把 `binlog 写入磁盘`
- 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交`commit`状 态，更新完成

### 组提交
- 一次组提交里面，组员越多，节约磁盘 IOPS 的效果越好

### 崩溃恢复时的判断规则
- 如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交
- 如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完 整： 
    - 是，则提交事务
    - 否，回滚事务

#### 怎么判断binlog是完整的？
- statement 格式的 binlog，最后会有 COMMIT
- row 格式的 binlog，最后会有一个 XID event

## 主从复制
### 流程
![image](6.日志.assets/9566)
- 在备库 B 上通过 `change master` 命令，设置主库 A 的 IP、端口、用户名、密码，以及要 从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量
- 在备库 B 上执行 `start slave` 命令，这时候备库会启动两个线程，就是图中的 `io_thread` 和 `sql_thread`，其中 `io_thread 负责与主库建立连接`
- 主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，通过`binary log dump`线程发给B
- 备库 B 拿到 binlog 后，写到本地文件，称为`中转日志（relay log）`
- `sql_thread` 读取中转日志，解析出日志里的命令，并执行

#### 主节点 binary log dump 线程
- 当从节点连接主节点时，主节点会创建一个log dump 线程，用于发送bin-log的内容
- 在读取bin-log中的操作时，此线程会对主节点上的bin-log加锁，当读取完成，甚至在发动给从节点之前，锁会被释放

#### 从节点I/O线程
- 当从节点上执行`start slave`命令之后，从节点会创建一个I/O线程用来连接主节点，请求主库中更新的bin-log
- I/O线程接收到主节点binlog dump 进程发来的更新之后，保存在本地relay-log中

#### 从节点SQL线程
- SQL线程负责读取relay log中的内容，解析成具体的操作并执行，最终保证主从数据的一致性

### 双M结构下，循环复制问题解决
- 从节点 A 更新的事务，binlog 里面记的都是 A 的 server id
- 传到节点 B 执行一次以后，节点 B 生成的 binlog 的 server id 也是 A 的 server id
- 再传回给节点 A，A 判断到这个 server id 与自己的相同，就不会再处理这个日志，所以， 死循环在这里就断掉了

